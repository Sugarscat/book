# 机器学习

::: tip 快速入门
推荐课程：[李宏毅2023春机器学习课程](https://www.bilibili.com/video/BV1Wv411h7kN)
:::

## 引入

1. `ChatGPT` 实现基本原理：文字接龙；

   `BERT` 实现的基本原理是：文字填空。

2. 预训练模型→下游模型

   预训练模型（基石模型）：自督导式学习。

   下游模型：督导式学习→增强式学习（由人类干涉）。

::: tip 提示
`ChatGPT`：自督导式→督导式学习→增强式学习。

自督导式：学会文字接龙；

督导式学习：学会正确的文字接龙；

增强式学习：学会更好的文字接龙。
:::

## 基础

1. 机器学习 ≈ 机器自动找到一个函式。

2. 根据函式的输出分类：

   - 回归：函式的输出是一个数值；

   - 分类：函式的输出是一个类别。

::: tip 提示
`ChatGPT`：属于分类，把生成式学习拆解成多个分类问题。
:::

3. 找函式的三个步骤：

   - 设定范围 —— 定出候选函式的集合（Model）；

   - 设定标准 —— 定出【评量函式好坏】的标准（Loss）；

   - 达成目标 —— 找出最好的函式。

::: tip 提示
`CNN,RNN,Transformer(类神经网络结构)`  就是候选函式的集合。
:::

## 生成式学习

### 两种策略

> 各个击破、一次到位。

1. 各个击破：

   - 速度较慢：一次只生成一个元素，每个元素都要等前一个元素生成。
   - 品质更好。

2. 一次到位：

   - 速度快：只要有足够的平行算力，就可以完全生成。

   - 品质较差。
   

推荐：各个击破 + 一次到位

- 以各个击破为基础，再一次到位；
- N次到位。

### 两种不同期待

1. 成为通才：适用于各种任务，可以快速开发出新的功能；

2. 成为专才：在单一任务上会比通才较好。

### 对预训练的模型进行改造

1. 微调：把模型的原来参数当作初始化参数，使用梯度下降法对模型进行微调。
2. Adapter(适配器)：不改动模型的参数，为模型提供额外的模组（适应更多的任务）。

## In-context Learning

> 情境学习

为机器提供标注的范例进行“学习” —— 模型其实本来就会情境分析，只是需要被指出需要做情

境任务。

